# 카프카 기초 학습 및 사용 보고서

Apache Kafka는 분산형 스트리밍 플랫폼으로, 대규모 데이터 처리와 비동기 이벤트 기반 시스템에 적합한 메시지 브로커입니다.
LinkedIn에서 개발되어 현재는 오픈소스로 운영 중입니다.

## Kafka 구성 요소

| 구성 요소              | 설명                                                                 |
|------------------------|----------------------------------------------------------------------|
| **Producer**            | 메시지를 Kafka로 전송하는 주체 (이벤트 발행자)                      |
| **Consumer**            | Kafka로부터 메시지를 읽는 주체 (이벤트 수신자)                      |
| **Topic**               | 메시지를 분류하는 단위. 하나의 토픽에 여러 메시지가 저장됨         |
| **Broker**              | Kafka 서버. 여러 개가 클러스터로 구성됨                            |
| **Partition**           | 토픽 내 데이터의 분산 단위. 성능 확장성과 병렬 처리를 가능하게 함   |
| **Offset**              | 각 메시지의 고유 위치. Consumer는 이 위치를 기준으로 메시지 처리    |
| **Consumer Group**      | 여러 Consumer를 묶는 단위. 병렬 처리를 위한 구조                    |
| **Zookeeper (또는 KRaft)** | 클러스터 메타데이터 관리 (신버전에서는 Zookeeper 없이도 운영 가능)  |


## Kafka 메시지 처리 흐름
Producer가 특정 Topic에 메시지를 전송

메시지는 해당 Topic의 Partition에 저장됨

Consumer는 Topic의 Partition을 구독하여 메시지를 읽음

메시지는 디스크에 저장되며, 특정 기간까지 유지됨 (retention 설정 가능)

## Kafka의 특징

| 항목                | 설명                                                              |
|---------------------|-------------------------------------------------------------------|
| **내구성**           | 메시지를 디스크에 저장하여 장애 발생 시에도 손실 방지             |
| **확장성**           | Partition 수를 늘려서 수평 확장 가능                              |
| **고성능**           | 수천 TPS 이상도 처리 가능한 구조                                   |
| **복수 Consumer 지원** | 하나의 메시지를 여러 시스템에서 각각 처리 가능                    |
| **리플레이 지원**     | Offset을 기준으로 과거 메시지 재처리 가능                         |


## 메시지 처리 방식

| 처리 방식        | 설명                                                              |
|------------------|-------------------------------------------------------------------|
| **At most once**  | 한 번 이상 안 보낼 수도 있음 (손실 위험)                         |
| **At least once** | 적어도 한 번 전달됨 (중복 가능성 있음)                          |
| **Exactly once**  | 단 한 번만 전달됨 (Kafka + 트랜잭션 사용 시 구현 가능)           |


## Kafka 관련 필수 용어 정리

| 용어            | 설명                                                              |
|-----------------|-------------------------------------------------------------------|
| **Topic**        | 메시지를 구분하기 위한 채널                                       |
| **Partition**    | 메시지를 나누어 저장하는 단위 (병렬성 향상)                      |
| **Offset**       | 메시지 위치 값 (Consumer가 저장함)                               |
| **Consumer Group** | 여러 Consumer가 병렬로 하나의 Topic을 처리할 수 있게 구성       |
| **Retention**    | 메시지 보관 기간 설정 (예: 7일)                                  |
| **Broker**       | Kafka 서버 인스턴스                                              |



## Kafka 기반 이벤트 처리 방식 도입과 장점 분석

### 1. 학습 배경
기존 시스템에서는 결제 완료 시 주문 정보를 데이터 플랫폼으로 전달하기 위해 Spring의 @EventListener 기반 이벤트 발행 방식을 사용하고 있었다. 이 방식은 간단하고 구현이 빠르다는 장점이 있으나, 마이크로서비스 아키텍처(MSA) 확장과 장애 복원 측면에서 한계를 갖고 있었다. 이에 따라 Kafka 기반의 메시지 발행/구독(Event Streaming) 방식으로의 전환 필요성을 검토하게 되었다.

### 2. 기존 방식: Spring Event 처리 방식
Spring 내부의 ApplicationEventPublisher와 @EventListener를 사용

같은 JVM 내에서 동작하며, 발행자와 소비자가 동일 애플리케이션에 있어야 함

동기/비동기 처리가 가능하지만, 기본적으로 프로세스 내부에 한정됨

단점

| 항목       | 설명                                                                |
|------------|---------------------------------------------------------------------|
| 결합도     | 발행자와 소비자가 코드 레벨로 강하게 연결되어 있음                 |
| 장애 복원  | 예외 발생 시 재처리나 복구 로직이 직접 구현되어야 함              |
| 확장성     | 외부 시스템 연계에 불리, 새로운 소비자 추가가 어려움              |
| 모니터링   | 메시지 흐름을 추적하거나 실패 내역을 파악하기 어려움              |


### 3. 개선안: Kafka 기반 이벤트 처리 방식
Kafka는 분산형 메시지 브로커로, 발행자와 소비자가 완전히 분리되어 통신한다. Kafka 기반으로 전환할 경우 다음과 같은 장점이 있다:

✅ 주요 장점

| 항목             | 설명                                                             |
|------------------|------------------------------------------------------------------|
| 느슨한 결합       | Producer와 Consumer가 완전히 분리되어 독립 배포 가능             |
| 확장성           | 하나의 이벤트에 대해 복수 시스템이 각각 처리 가능               |
| 신뢰성           | 메시지를 디스크에 저장하고 복제하여 손실 가능성 최소화          |
| 장애 복원력      | Consumer가 죽었다가 살아나도 메시지 재처리 가능                 |
| 리플레이 기능     | 메시지를 재처리하거나 다시 보내는 기능이 내장됨                 |
| 모니터링/트레이싱 | Kafka 모니터링 도구를 통한 메시지 흐름 추적 가능               |

### 4. DLQ(Dead Letter Queue) 적용
Kafka를 도입함에 따라, 메시지 처리 실패 시 유실을 방지하고 문제 원인을 추적할 수 있도록 DLQ(Dead Letter Queue) 를 함께 적용하였다.

DLQ 적용 목적

데이터 유실 방지: 실패한 메시지를 따로 저장

문제 분석: 어떤 이유로 실패했는지 기록 가능

재처리 용이성: 운영자 혹은 자동 프로세스가 실패 메시지를 다시 처리 가능

적용 방식 요약

Spring Kafka의 DeadLetterPublishingRecoverer와 DefaultErrorHandler를 활용

메시지 처리 실패 시 자동으로 <topic>.DLT 토픽으로 메시지 이동

재시도(FixedBackOff) 후에도 실패하면 DLQ로 격리

DLQ 토픽에 대한 별도 Consumer 구성 가능

| 구성 요소                   | 설명                                                    |
|----------------------------|---------------------------------------------------------|
| **DeadLetterPublishingRecoverer** | 실패 메시지를 DLQ 토픽으로 전달하는 로직                   |
| **DefaultErrorHandler**          | 재시도 횟수 및 DLQ 전송 시점 설정                          |
| **.DLT 토픽**                    | 원래 메시지 토픽명 + `.DLT` 접미어로 생성되는 DLQ 토픽     |


### 5. Spring Event vs Kafka 비교
| 항목           | Spring Event 방식             | Kafka 방식                 |
|----------------|-------------------------------|--------------------------|
| 결합도         | 높음 (JVM 내부 결합)          | 낮음 (완전 분리)               |
| 확장성         | 낮음                          | 매우 높음                    |
| 장애 복원      | 수동 처리 필요                | 자동 재처리 및 복구 가능           |
| 데이터 신뢰성  | 메모리 기반, 유실 위험 존재   | 디스크 저장, 복제, 유실 위험에 안전    |
| 소비자 추가    | 어려움                        | 쉬움                       |
| 이벤트 추적    | 불가능 또는 제한적            | 완전 가능 (offset, topic 기반) |


### 6. 결론 및 도입
Kafka 기반 이벤트 처리는 시스템 확장성과 안정성 측면에서 기존 Spring Event 방식보다 명확한 이점을 제공한다. 특히 MSA 구조에서 각 도메인의 독립성과 장애 대응력을 높이기 위한 구조로 적합하다.

향후 결제 완료 이벤트 외에도 사용자 알림, 재고 연동, 분석 파이프라인 등 다양한 이벤트를 Kafka 기반으로 전환함으로써 시스템의 유연성과 운영 안정성을 높일 수 있을 것으로 기대된다.